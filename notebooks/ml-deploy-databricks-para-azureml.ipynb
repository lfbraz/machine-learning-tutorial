{"cells":[{"cell_type":"markdown","source":["# Deploy de Modelos de Machine Learning\n\n### Exemplo de deployment utilizando Azure Databricks e Azure Machine Learning\n\nNeste tutorial demonstraremos como realizar o deployment de modelos de Machine Learning com modelos j√° treinados anteriormente. \n\nUtilizaremos o [Azure Databricks](https://azure.microsoft.com/pt-br/services/databricks/) para carregamento dos modelos e posterior cria√ß√£o das APIs de consumo realizando sua conex√£o com o [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/). \n\nEste tutorial foi inspirado nos notebooks [MLflow Quick Start Part 1: Training and Logging](https://docs.azuredatabricks.net/_static/notebooks/mlflow/mlflow-quick-start-training.html) e [Quick Start Part 2: Serving Models with Azure ML](https://docs.azuredatabricks.net/_static/notebooks/mlflow/mlflow-quick-start-deployment-azure.html). Para maiores detalhes aconselho fortemente sua leitura ü§ì"],"metadata":{}},{"cell_type":"markdown","source":["### Modelo de Machine Learning de Regress√£o Linear para previs√£o do pre√ßo de venda de Carros Usados\nUtilizaremos neste tutorial um modelo de Regress√£o Linear Simples j√° previamente treinado com dados de vendas de ve√≠culos usados. Os passos para treinamento e persist√™ncia deste modelo podem ser encontrados [aqui](https://github.com/lfbraz/machine-learning-tutorial/blob/master/notebooks/ml-modelo-regressao-carros-usados.ipynb).\n\nEste tutorial pode ser utilizado com outros tipos de modelo de Machine Learning para atua√ß√£o em diferentes cen√°rios (Problemas de classifica√ß√£o, NLP, etc) em que os passos ser√£o semalhantes (basta previamente ter persistido o modelo).\n\nFique a vontade para adaptar conforme sua necessidade üòâ"],"metadata":{}},{"cell_type":"markdown","source":["## Instala√ß√£o das bibliotecas\nSer√° necess√°rio o uso da biblioteca OpenSource [`mlflow`](https://mlflow.org/) que permite a organiza√ß√£o e monitoramento de m√©tricas e execu√ß√µes associadas ao treinamento dos modelos de Machine Learning, e tamb√©m o [`azureml-sdk`](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py) que permite a cria√ß√£o e manipula√ß√£o de Workspaces do [Azure Machine Learning](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py) utilizando linguagem Python.\n\nPara instala√ß√£o das bibliotecas no Databricks utilizaremos o comando `dbutils.library.installPyPi` que basicamente instala os pacotes utilizando o reposit√≥rio [`PyPi`](https://pypi.org/). No Databricks esta forma de instala√ß√£o de bibliotecas faz com que elas sejam instaladas apenas no contexto do pr√≥prio notebook. Para outros m√©todos de instala√ß√£o (Cluster, Workspace, etc) consulte a [documenta√ß√£o](https://docs.microsoft.com/en-us/azure/databricks/libraries#library-modes).\n\nCaso esteja utilizando outras plataformas para desenvolvimento de modelos, utilizar o comando apropriado para instala√ß√£o das bibliotecas seguindo o reposit√≥rio `PyPi`."],"metadata":{}},{"cell_type":"code","source":["dbutils.library.installPyPI(\"mlflow\", extras=\"extras\")\n\ndbutils.library.installPyPI(\"azureml-sdk\")\ndbutils.library.restartPython()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##Carregamento do modelo de Machine Learning previamente treinado\nConforme dito anteriormente utilizaremos um modelo [j√° treinado](https://github.com/lfbraz/machine-learning-tutorial/blob/master/notebooks/ml-modelo-regressao-carros-usados.ipynb) em que basicamente adaptaremos o caminho do diret√≥rio (do modelo persistido) nas vari√°veis `NOME_MODELO` e `CAMINHO_MODELO`.\n\nCom isso, faremos o carregamento do modelo utilizando o `LinearRegressionModel`. <br/><br/>\n\n* **IMPORTANTE**: √â necess√°rio que voc√™ saiba previamente qual o tipo de modelo que ser√° carregado para que possa instanciar da forma correta a biblioteca mais apropriada. No caso deste tutorial sab√≠amos previamente se tratar de um modelo de Regress√£o Linear treinado utilizando PySpark."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import PipelineModel\n\nNOME_MODELO = 'modelo_regressao_linear.model'\nCAMINHO_MODELO = '/mnt/models/{}'.format(NOME_MODELO)\n\nmodel = PipelineModel.load(CAMINHO_MODELO)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["###Carregar os dados para *\"PREVIS√ÉO\"* do modelo\nAgora vamos carregar alguns dados para que seja poss√≠vel *testarmos* o modelo que carregamos. Como o objetivo deste tutorial √© apenas analisarmos o processo de *deployment* utilizaremos o mesmo [arquivo](https://github.com/lfbraz/machine-learning-tutorial/blob/master/datasets/dataset-carros-usados.csv) de treino do modelo que j√° havia sido previamente importado para o Databricks (vide se√ß√£o *Importar base de dados* do [link](https://github.com/lfbraz/machine-learning-tutorial/blob/master/notebooks/ml-modelo-regressao-carros-usados.ipynb))."],"metadata":{}},{"cell_type":"code","source":["file_type = \"csv\"\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \";\"\noutput_dbfs_file_path = '/data/dataset-carros-usados.csv'\n\ncarros_usados = spark.read.format(file_type) \\\n                     .option(\"inferSchema\", infer_schema) \\\n                     .option(\"header\", first_row_is_header) \\\n                     .option(\"sep\", delimiter) \\\n                     .load(output_dbfs_file_path)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Tratamento dos dados\nAssim como na etapa de *treinamento* do modelo, precisamos agora realizar o *tratamento dos dados* antes da predi√ß√£o.\n\nOs tratamentos que foram realizados em um `pipeline` n√£o precisam ser refeitos (pois ser√£o aplicados diretamente pelo modelo). \nAqui apenas precisamos remover os valores *NULOS* (conforme realizado no [tutorial](https://github.com/lfbraz/machine-learning-tutorial/blob/master/notebooks/ml-modelo-regressao-carros-usados.ipynb)).\n\nOs dados tratados ser√£o segmentados randomicamente em duas bases chamadas `validacao1` e `validacao2` utilizando o mesmo arquivo de dados utilizados no treinamento (faremos isso apenas para facilitar a demonstra√ß√£o, pois o objetivo aqui n√£o √© avaliar a performance do modelo)."],"metadata":{}},{"cell_type":"code","source":["carros_usados = carros_usados.na.drop()\nvalidacao1, validacao2 = carros_usados.randomSplit([0.5, 0.5])"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["predicoes = model.transform(validacao1)\npredicoes.show(n=5)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Predi√ß√£o\nAgora podemos chamar o m√©todo `transform` do modelo carregado para realizar as predi√ß√µes `ad-hoc`."],"metadata":{}},{"cell_type":"code","source":["predicoes = model.transform(validacao1)\npredicoes.show(n=5)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["##Persistir o modelo utilizando o MLFlow\nAgora precisamos utilizar a biblioteca `mlflow` para persistirmos o modelo e registrarmos uma execu√ß√£o associada a ele. Esta etapa √© importante pois utilizaremos posteriormente o `run_id` vinculado a esta execu√ß√£o. Precisamos tamb√©m associar um nome de modelo (vari√°vel `NOME_MODELO_DEPLOY`) e caminho (vari√°vel `modelpath`) onde este ser√° persistido (agora no formato mlflow).\n\nNeste tutorial estamos utilizando um modelo `spark` por√©m existem outras possibilidades por exemplo utilizando `sklearn`, entre outros."],"metadata":{}},{"cell_type":"code","source":["import mlflow.spark\nNOME_MODELO_DEPLOY = 'modelo-regressao-linear-tutorial'\n\nwith mlflow.start_run():\n  # Log the model\n  mlflow.spark.log_model(model, NOME_MODELO_DEPLOY)\n  \n  # Persist the model in dbfs\n  modelpath = '/dbfs/mlflow/model-linear-regression/{}'.format(NOME_MODELO_DEPLOY)\n  mlflow.spark.save_model(model, modelpath)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## Criar/Utilizar Workspace do Azure Machine Learning\nUtilizamos o Azure Machine Learning para disponibiliza√ß√£o dos `endpoints` das APIs que ir√£o consumir os modelos de Machine Learning. Para intera√ß√£o com ele, vamos utilizar o [Azure Machine Learning SDK](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py) em Python, em que √© poss√≠vel criar novas Workspaces (ou utilizar Workspaces existentes) para facilitar o processo de deployment.\n\n√â necess√°rio preencher as vari√°veis `WORKSPACE_NAME`, `WORKSPACE_LOCATION`, `RESOURCE_GROUP` e `SUBSCRIPTION_ID` com os dados da assinatura Azure que ser√° utilizada para disponibiliza√ß√£o do Azure Machine Learning.\n\nPara o `run_id` deve-se pegar coletar este dado a partir da execu√ß√£o realizada acima:\n\nPara isso seguir o exemplo abaixo:\n\n1. Clicar no √≠cone **Runs** na barra de contexto do Notebook. Nele √© poss√≠vel visualizar as execu√ß√µes, m√©tricas e par√¢metros. Por exemplo: <img src=\"https://docs.databricks.com/_static/images/mlflow/mlflow-notebook-experiments.gif\"/>\n   \n1. Clicar no √≠cone **External Link** <img src=\"https://docs.databricks.com/_static/images/external-link.png\"/> in the Runs context bar to view the notebook experiment. For example: <img src=\"https://docs.databricks.com/_static/images/mlflow/quick-start-nb-experiment.png\"/>\n\n![image](https://docs.azuredatabricks.net/_static/images/mlflow/mlflow-deployment-example-run-info.png)"],"metadata":{}},{"cell_type":"markdown","source":["Com isso podemos agora construir a imagem contendo o modelo e disponibiliz√°-lo no Azure Machine Learning."],"metadata":{}},{"cell_type":"code","source":["import azureml\nfrom azureml.core import Workspace\nimport mlflow.azureml\n\nWORKSPACE_NAME = '<NOME_WORKSPACE>'\nWORKSPACE_LOCATION = '<REGIAO_WORKSPACE>'\nRESOURCE_GROUP = '<NOME_RESOURCE_GROUP>'\nSUBSCRIPTION_ID = '<ID_SUBSCRICAO>'\n\nNOME_IMAGEM = 'model-image-linear-regression'\nDESCRICAO_IMAGEM = 'Modelo de Regress√£o Linear - Tutorial'\n\nworkspace = Workspace.create(name = WORKSPACE_NAME,\n                             location = WORKSPACE_LOCATION,\n                             resource_group = RESOURCE_GROUP,\n                             subscription_id = SUBSCRIPTION_ID,\n                             exist_ok=True)\n\nrun_id1 = '<RUN_ID>'\nmodel_uri = 'runs:/' + run_id1 + '/{}'.format(NOME_MODELO_DEPLOY)\n\nmodel_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri, \n                                                      workspace=workspace,\n                                                      model_name=NOME_MODELO_DEPLOY,\n                                                      image_name=NOME_IMAGEM,\n                                                      description=DESCRICAO_IMAGEM,\n                                                      synchronous=False)\n\nmodel_image.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["Por padr√£o ser√° solicitada a autentica√ß√£o utilizando o `Interactive Login`. Para cen√°rios produtivos deve-se utilizar um registro de aplica√ß√£o com `Service Principal`. Na [documenta√ß√£o](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication#set-up-service-principal-authentication) temos uma explica√ß√£o mais detalhada dos diferentes tipos de autentica√ß√£o."],"metadata":{}},{"cell_type":"markdown","source":["#Deploy\nAgora com a imagem criada, podemos escolher dois tipos de deployment, utilizando `ACI` (Azure Container Image) ou `AKS` (Azure Kubernetes Service).\n\nPara cen√°rios de desenvolvimento √© indicado o uso do `ACI` j√° para cen√°rios produtivos `AKS` ter√° melhores op√ß√µes quanto a seguran√ßa e escalabilidade."],"metadata":{}},{"cell_type":"markdown","source":["##ACI - Azure Container Image\nAbaixo ser√° demonstrado como criar um `endpoint` utilizando o `ACI`. Lembrando que estaremos utilizando o Workspace instanciado no passo anterior."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice, Webservice\n\nNOME_WEBSERVICE = 'linear-model-webservice'\n\n#TODO: Change deploy_from_image to environments (https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments)\n\ndev_webservice_deployment_config = AciWebservice.deploy_configuration()\ndev_webservice = Webservice.deploy_from_image(name=NOME_WEBSERVICE, \n                                              image=model_image, \n                                              deployment_config=dev_webservice_deployment_config, \n                                              workspace=workspace)\n\ndev_webservice.wait_for_deployment()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Com isso a API j√° dever√° ter sido criada a partir de um `ACI`. Podemos analisar no Azure Machine Learning o modelo criado:\n\n<img src=\"https://github.com/lfbraz/machine-learning-tutorial/blob/master/images/azure-ml-models.PNG?raw=true\"/>\n\nE tamb√©m o endpoint:\n\n<img src=\"https://github.com/lfbraz/machine-learning-tutorial/blob/master/images/azure-ml-endpoints.PNG?raw=true\"/>"],"metadata":{}},{"cell_type":"markdown","source":["###Predi√ß√£o com o uso da API (Real-time endpoint)\nAgora vamos utilizar o DataFrame `validacao1` (removendo a coluna target *PRECO*) para valida√ß√£o da API criada no Azure Machine Learning. \n\nA API espera que o *INPUT* esteja no formato `json`, ent√£o vamos realizar a formata√ß√£o convertendo para um DataFrame `pandas` que possui o m√©todo `to_json`, facilitando a execu√ß√£o deste processo. Tamb√©m √© necess√°rio que seja utilizado o par√¢metro `orient=\"split\"` para que a formata√ß√£o do `json` esteja de acordo com o que √© esperado pela API.\n\nNeste exemplo, faremos uma chamada utilizando apenas uma linha do DataFrame original (`validacao1`), por√©m a API suporta a execu√ß√£o em `batch` com v√°rias linhas sendo enviadas no mesmo `json` (para isso basta aumentar o range de sele√ß√£o no m√©todo `iloc`)."],"metadata":{}},{"cell_type":"code","source":["sample = validacao1.toPandas().drop('PRECO', axis=1)\nsample = sample.iloc[0:1,:]\nquery_input = sample.to_json(orient=\"split\")"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["# Chamada da API\nFinalmente faremos o *request* da API utilizando a vari√°vel `query_input`. A URL da API pode ser obtida atrav√©s do `dev_webservice.scoring_uri` que foi gerado no deploy do endpoint."],"metadata":{}},{"cell_type":"code","source":["import requests\nimport json\n\ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n  \n  print('URI: {}'.format(scoring_uri))\n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=json.loads(json.dumps(inputs)), headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds\n\nquery_endpoint_example(scoring_uri=dev_webservice.scoring_uri, inputs=query_input)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["Tamb√©m √© poss√≠vel utilizar a API via qualquer aplicativo cliente para chamadas HTTP (curl, postman, etc)."],"metadata":{}},{"cell_type":"markdown","source":["## Azure Kubernetes Services (AKS)\nPara cen√°rios produtivos, uma melho op√ß√£o de deploy √© utilizando um [`AKS`](https://azure.microsoft.com/pt-br/overview/kubernetes-getting-started/) que traz maiores benef√≠cios quanto a seguran√ßa e escalabilidade.\n\nNeste cen√°rio com `AKS` √© poss√≠vel seguirmos com o Deploy de duas formas: Criando um novo cluster AKS ou realizando o deploy em um cluster existente. Neste tutorial demonstraremos a primeira op√ß√£o. No [link](https://docs.azuredatabricks.net/_static/notebooks/mlflow/mlflow-quick-start-deployment-azure.html) √© poss√≠vel analisar o processo utilizando um cluster j√° existente (se√ß√£o *\"Connect to an existing AKS cluster\"*)."],"metadata":{}},{"cell_type":"markdown","source":["####Criar um novo Cluster"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.compute import AksCompute, ComputeTarget\n\n# Use the default configuration (you can also provide parameters to customize this)\nprov_config = AksCompute.provisioning_configuration()\n\naks_cluster_name = \"aks-cluster\"\n\n# Create the cluster\naks_target = ComputeTarget.create(workspace = workspace, \n                                  name = aks_cluster_name, \n                                  provisioning_configuration = prov_config)\n\n# Wait for the create process to complete\naks_target.wait_for_completion(show_output = True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Agora podemos fazer o deploy do webservice utilizando o novo cluster AKS"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import Webservice, AksWebservice\n\n# Set configuration and service name\nprod_webservice_name = \"linear-regression-model-prod\"\nprod_webservice_deployment_config = AksWebservice.deploy_configuration()\n\n# Deploy from image\nprod_webservice = Webservice.deploy_from_image(workspace = workspace, \n                                               name = prod_webservice_name,\n                                               image = model_image,\n                                               deployment_config = prod_webservice_deployment_config,\n                                               deployment_target = aks_target)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["E agora realizar uma chamada da API para testarmos seu funcionamento. Neste caso ser√° necess√°rio utilizar um `key` para autentica√ß√£o da API que pode ser obtida atrav√©s do m√©todo `get_keys()`."],"metadata":{}},{"cell_type":"code","source":["prod_scoring_uri = prod_webservice.scoring_uri\nprod_service_key = prod_webservice.get_keys()[0] if len(prod_webservice.get_keys()) > 0 else None"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)"],"metadata":{},"outputs":[],"execution_count":36}],"metadata":{"name":"ml-deploy-databricks-para-azureml","notebookId":2072874032304060},"nbformat":4,"nbformat_minor":0}
